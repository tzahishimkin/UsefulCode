{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Present methods of how to use\n",
    "2. Present full code usage\n",
    "\n",
    "### Resources\n",
    "- My Youtube guy - 5 minutes expalantion- Very useful <br> https://www.youtube.com/watch?time_continue=297&v=3bownM3L5zM\n",
    "- Tensorboard in 5 minutes: <br> https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n",
    "- Tensorboard Notebook example(Recommanded) <br> https://github.com/swirlingsand/tensorboard-rnn-example/blob/master/Tensorboard%20example.ipynb\n",
    "- Thorough TF tutorial <br> https://www.datacamp.com/community/tutorials/tensorboard-tutorial\n",
    "- Tensorboard page: <br>https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n",
    "- Tensorboard Git (Useful): <br>https://github.com/tensorflow/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use\n",
    "There are two ways to add data to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Adding a variable to tf.summary\n",
    "There are multiple actions TF knows to do on objects. \n",
    "\n",
    "List of actions:\n",
    "https://www.tensorflow.org/api_guides/python/summary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.summary.histogram(“your_variable_name”, your_variable)\n",
    "example:\n",
    "softmax_w = tf.Variable(tf.truncated_normal( (in_size, ...)\n",
    "tf.summary.histogram(“softmax_w”, softmax_w)\n",
    "predictions = tf.nn.softmax(logits, name=\"predictions\")\n",
    "tf.summary.histogram(\"predictions\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Function\n",
    "\n",
    "1. tf.summary.image: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Save variabes During Training\n",
    "Stages:\n",
    "- In your tf.Session() define a writer.\n",
    "- In your training loop, define a merge with tf.summary.merge_all().\n",
    "- In sess.run() pass merge (a Tensor), get back a summary.\n",
    "- Add summary to your writer. Done."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "  train_writer = tf.summary.FileWriter( './logs/1/train ', sess.graph)\n",
    "\n",
    "  counter = 0\n",
    "  for e in range(epochs)\n",
    "    for x, y in get_batches(....):\n",
    "      counter += 1\n",
    "      \n",
    "      merge = tf.summary.merge_all()\n",
    "\n",
    "      summary, batch_loss, new_state, _ = sess.run([merge,      model.loss, model.final_state, model.optimizer],feed_dict=feed)\n",
    "\n",
    "      train_writer.add_summary(summary, counter)\n",
    "\n",
    "      # .... your code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Start the training\n",
    "- In terminal run Tensorboard:  tensorboard --logdir logs/1\n",
    "- In browser go to URL provided: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Next Step - Add Name Scopes\n",
    "It is assential to add name scope to your function and quite eay to do it after the code. <br>\n",
    " Just add tf.name_scope() to the functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.name_scope(“RNN_init_state”):\n",
    "  initial_state = rnn_cells.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def init_weights(shape, name):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
    "\n",
    "def model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden):\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        X = tf.nn.dropout(X, p_keep_input)\n",
    "        h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        h = tf.nn.dropout(h, p_keep_hidden)\n",
    "        h2 = tf.nn.relu(tf.matmul(h, w_h2))\n",
    "    with tf.name_scope(\"layer3\"):\n",
    "        h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    return tf.matmul(h2, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Get input data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Create input and output placeholders\n",
    "X = tf.placeholder(\"float\", [None, 784] , name=\"X\")\n",
    "Y = tf.placeholder(\"float\", [None, 20] , name=\"Y\")\n",
    "\n",
    "# Step 3 - Initiliaze weights:\n",
    "w_h = init_weights([784, 625], \"w_h\")\n",
    "w_h2 = init_weights([625, 625], \"w_h2\")\n",
    "w_o = init_weights([625, 10], \"w_o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'w_o_sum_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - Add histogram summaries:\n",
    "tf.summary.histogram(\"w_h_sum\", w_h)\n",
    "tf.summary.histogram(\"w_h2_sum\", w_h2)\n",
    "tf.summary.histogram(\"w_o_sum\", w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Add dropout to input and hidden layers:\n",
    "p_keep_input = tf.placeholder(\"float\", name=\"p_keep_input\")\n",
    "p_keep_hidden = tf.placeholder(\"float\", name=\"p_keep_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Create model:\n",
    "p_x = model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - Create cost function:\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=p_x,labels=Y))\n",
    "    train_op = tf.train.RMSPropOptimizer(learning_rate=0.001, decay=0.9).minimize(cost)\n",
    "    # Add scalar summary for cost tensor:\n",
    "    tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 - Measure Acuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.arg_max(Y,1), tf.arg_max(p_x,1))\n",
    "    acc_op = tf.reduce_mean(tf.cast(correct_pred, \"float\")) #Cast boolean to float to get average\n",
    "    tf.summary.scalar(\"accuracy\", acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e3c8b589369d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 9 - Create Session\n",
    "\n",
    "# Merge all the summaries and write them out to\n",
    "log_dir ='/tmp/tensorflow/mnist/logs/mnist_with_summaries' \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 10 - Create a log writer. Run 'tensorboard --logdir=\"log_dir\"'\n",
    "    writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    # Step 11 - Initializa al variables:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # Step 12 - Train he model\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128))\n",
    "        #Note - the range thing is a nice way to get [0,128,256,....]\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end], p_keep_input: 0.8, p_keep_hidden: 0.5})\n",
    "        summary, acc = sess.run([merged, acc_op], feed_dict={X: trX[start:end], Y: trY[start:end], p_keep_input: 1, p_keep_hidden: 1})\n",
    "        writer.add_summary(summary, i)\n",
    "        print(i, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
