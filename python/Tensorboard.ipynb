{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Present methods of how to use\n",
    "2. Present full code usage\n",
    "\n",
    "### Resources\n",
    "- [My Youtube guy](https://www.youtube.com/watch?time_continue=297&v=3bownM3L5zM) - 5 minutes expalantion- Very useful\n",
    "- [Tensorboard in 5 minutes](https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af) - quick referance \n",
    "- [Tensorboard Notebook example](https://github.com/swirlingsand/tensorboard-rnn-example/blob/master/Tensorboard%20example.ipynb) Recommanded\n",
    "- [Datacamp tutorial](https://www.datacamp.com/community/tutorials/tensorboard-tutorial) - Thorough TensorBoard tutorial \n",
    "- [Tensorboard page](https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af)\n",
    "- [Oficial Tensorboard Git](https://github.com/tensorflow/tensorboard) - Very Useful, with many commands and expalantios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use\n",
    "There are two ways to add data to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Adding a variable to tf.summary\n",
    "There are multiple actions TF knows to do on objects. \n",
    "\n",
    "List of actions:\n",
    "https://www.tensorflow.org/api_guides/python/summary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.summary.histogram(“your_variable_name”, your_variable)\n",
    "example:\n",
    "softmax_w = tf.Variable(tf.truncated_normal( (in_size, ...)\n",
    "tf.summary.histogram(“softmax_w”, softmax_w)\n",
    "predictions = tf.nn.softmax(logits, name=\"predictions\")\n",
    "tf.summary.histogram(\"predictions\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Function\n",
    "\n",
    "1. tf.summary.image: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Save variabes During Training\n",
    "Stages:\n",
    "- In your tf.Session() define a writer.\n",
    "- In your training loop, define a merge with tf.summary.merge_all().\n",
    "- In sess.run() pass merge (a Tensor), get back a summary.\n",
    "- Add summary to your writer. Done."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "  train_writer = tf.summary.FileWriter( './logs/1/train ', sess.graph)\n",
    "\n",
    "  counter = 0\n",
    "  for e in range(epochs)\n",
    "    for x, y in get_batches(....):\n",
    "      counter += 1\n",
    "      \n",
    "      merge = tf.summary.merge_all()\n",
    "\n",
    "      summary, batch_loss, new_state, _ = sess.run([merge,      model.loss, model.final_state, model.optimizer],feed_dict=feed)\n",
    "\n",
    "      train_writer.add_summary(summary, counter)\n",
    "\n",
    "      # .... your code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Start the training\n",
    "- In terminal run Tensorboard:  tensorboard --logdir logs/1\n",
    "- In browser go to URL provided: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Next Step - Add Name Scopes\n",
    "It is assential to add name scope to your function and quite eay to do it after the code. <br>\n",
    " Just add tf.name_scope() to the functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.name_scope(“RNN_init_state”):\n",
    "  initial_state = rnn_cells.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def init_weights(shape, name):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
    "\n",
    "def model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden):\n",
    "    with tf.name_scope(\"layer1\"):\n",
    "        X = tf.nn.dropout(X, p_keep_input)\n",
    "        h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    with tf.name_scope(\"layer2\"):\n",
    "        h = tf.nn.dropout(h, p_keep_hidden)\n",
    "        h2 = tf.nn.relu(tf.matmul(h, w_h2))\n",
    "    with tf.name_scope(\"layer3\"):\n",
    "        h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
    "    return tf.matmul(h2, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Get input data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Create input and output placeholders\n",
    "X = tf.placeholder(\"float\", [None, 784] , name=\"X\")\n",
    "Y = tf.placeholder(\"float\", [None, 20] , name=\"Y\")\n",
    "\n",
    "# Step 3 - Initiliaze weights:\n",
    "w_h = init_weights([784, 625], \"w_h\")\n",
    "w_h2 = init_weights([625, 625], \"w_h2\")\n",
    "w_o = init_weights([625, 10], \"w_o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'w_o_sum:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - Add histogram summaries:\n",
    "tf.summary.histogram(\"w_h_sum\", w_h)\n",
    "tf.summary.histogram(\"w_h2_sum\", w_h2)\n",
    "tf.summary.histogram(\"w_o_sum\", w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Add dropout to input and hidden layers:\n",
    "p_keep_input = tf.placeholder(\"float\", name=\"p_keep_input\")\n",
    "p_keep_hidden = tf.placeholder(\"float\", name=\"p_keep_hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Create model:\n",
    "p_x = model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 - Create cost function:\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=p_x,labels=Y))\n",
    "    train_op = tf.train.RMSPropOptimizer(learning_rate=0.001, decay=0.9).minimize(cost)\n",
    "    # Add scalar summary for cost tensor:\n",
    "    tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 - Measure Acuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.arg_max(Y,1), tf.arg_max(p_x,1))\n",
    "    acc_op = tf.reduce_mean(tf.cast(correct_pred, \"float\")) #Cast boolean to float to get average\n",
    "    tf.summary.scalar(\"accuracy\", acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f27028ae659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/tensorflow/mnist/logs/mnist_with_summaries'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Step 10 - Create a log writer. Run 'tensorboard --logdir=\"log_dir\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 9 - Create Session\n",
    "\n",
    "# Merge all the summaries and write them out to\n",
    "log_dir ='/tmp/tensorflow/mnist/logs/mnist_with_summaries' \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 10 - Create a log writer. Run 'tensorboard --logdir=\"log_dir\"'\n",
    "    writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    # Step 11 - Initializa al variables:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # Step 12 - Train he model\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "        #Note - the range thing is a nice way to get [0,128,256,....]\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end], p_keep_input: 0.8, p_keep_hidden: 0.5})\n",
    "        summary, acc = sess.run([merged, acc_op], feed_dict={X: trX[start:end], Y: trY[start:end], p_keep_input: 1, p_keep_hidden: 1})\n",
    "        writer.add_summary(summary, i)\n",
    "        print(i, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard on PyTorch\n",
    "\n",
    "You will need to install tensorboard-pytorch and tensorboardX:    pip intall tensorboard-pytorch tensorboardX \n",
    "<br>Check out [this](https://medium.com/@dexterhuang/tensorboard-for-pytorch-201a228533c5) source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage example:\n",
    "try:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    is_tensorboard_available = True\n",
    "except Exception:\n",
    "    is_tensorboard_available = False\n",
    "# Write you code\n",
    "writer = SummaryWriter('tensorboard_outputs') if is_tensorboard_available else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect TF-Record\n",
    "If you would like to inspect the content of a TF-Record. \n",
    "[Source](https://stackoverflow.com/questions/42394585/how-to-inspect-a-tensorflow-tfrecord-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "path_to.tfrecord; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ced4fd929176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path_to.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     reader = pywrap_tensorflow.PyRecordReader_New(\n\u001b[0;32m---> 74\u001b[0;31m         compat.as_bytes(path), 0, compat.as_bytes(compression_type), status)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: path_to.tfrecord; No such file or directory"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(\"path_to.tfrecord\"):\n",
    "    result = tf.train.Example.FromString(example)\n",
    "    \n",
    "# OR\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "...\n",
    "jsonMessage = MessageToJson(tf.train.Example.FromString(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF on Cloud\n",
    "\n",
    "1. Run tensorboard on the coud \n",
    "        tensorboard --logdir <path to file or dir containing the even logs> --port 6006  #port 6006 is the defualt port anyway\n",
    "    \n",
    "2. Once you run the TensoerBoard on the cloud on can connect to it via:\n",
    "        ssh -i ~/.ssh/shimkin_cloud_key -L 6006:127.0.0.1:6006 blink@35.231.131.217\n",
    "   In case you need to debug you can run:\n",
    "        ssh -L 6006:127.0.0.1:6006 blink@35.237.122.77 -N -v -v\n",
    "3. Now just open a browser and type: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debuggings:\n",
    "\n",
    "Error output:  (in the cloud)<br>\n",
    "    return _setlocale(category, locale)<br>\n",
    "locale.Error: unsupported locale setting<br>\n",
    "[Solution](https://github.com/tensorflow/tensorboard/issues/1323):<br>\n",
    "export LC_ALL=\"en_US.UTF-8\" <br>\n",
    "export LC_CTYPE=\"en_US.UTF-8\"<br>\n",
    "sudo dpkg-reconfigure locales<br>\n",
    "OR:<br>\n",
    "export LC_ALL=C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
